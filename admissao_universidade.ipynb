{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6316aa3-1377-45c5-8202-801ba2e0cdfd",
   "metadata": {},
   "source": [
    "# Previsão para admissão na faculdade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ef9806-f5af-4328-bbd4-56a4d4b063c2",
   "metadata": {},
   "source": [
    "## Introdução\n",
    "\n",
    "Baseado no [dataset](https://www.kaggle.com/datasets/safaruzzamanshovo/graduate-admission-dataset) do Kaggle, vou criar um modelo utilizando regressão linear que prevê a chance de admissão de novos alunos em universidades mediante seu histórico escolar e notas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168c87d4-6646-4698-8150-c67610de761d",
   "metadata": {},
   "source": [
    "## Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098cb8c8-1164-4e46-a332-3068b2e82128",
   "metadata": {},
   "source": [
    "### Carregando o DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e50e2d-af5d-4e3d-871b-2fd13656d939",
   "metadata": {},
   "source": [
    "Vamos começar importando as bibliotecas necessárias e carregar o dataset para começarmos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9cf2088-a6e2-40e2-b034-8969c4bc76b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>GPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>295</td>\n",
       "      <td>96</td>\n",
       "      <td>2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>340</td>\n",
       "      <td>119</td>\n",
       "      <td>3</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.7</td>\n",
       "      <td>3.76</td>\n",
       "      <td>0</td>\n",
       "      <td>0.708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>336</td>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.8</td>\n",
       "      <td>3.12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>337</td>\n",
       "      <td>108</td>\n",
       "      <td>4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.3</td>\n",
       "      <td>2.11</td>\n",
       "      <td>0</td>\n",
       "      <td>0.643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>323</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>3.40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GRE Score  TOEFL Score  University Rating  SOP  LOR    GPA  Research  \\\n",
       "0        295           96                  2  4.9   1.7  2.93         0   \n",
       "1        340          119                  3  4.1   1.7  3.76         0   \n",
       "2        336           96                  1  3.2   1.8  3.12         1   \n",
       "3        337          108                  4  3.4   1.3  2.11         0   \n",
       "4        323           98                  1  1.1   1.3  3.40         0   \n",
       "\n",
       "   Chance of Admit  \n",
       "0            0.612  \n",
       "1            0.708  \n",
       "2            0.728  \n",
       "3            0.643  \n",
       "4            0.524  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importando bibliotecas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Carregando o dataframe\n",
    "admission_df = pd.read_csv('graduate_admission.csv')\n",
    "\n",
    "# Mostrando as 5 primeiras linhas\n",
    "admission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ca4673f-b595-4679-af72-cdc118248b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Há 1000 linhas e 8 colunas.\n",
      "\n",
      "\n",
      "INFORMAÇÕES TÉCNICAS\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 8 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   GRE Score          1000 non-null   int64  \n",
      " 1   TOEFL Score        1000 non-null   int64  \n",
      " 2   University Rating  1000 non-null   int64  \n",
      " 3   SOP                1000 non-null   float64\n",
      " 4   LOR                1000 non-null   float64\n",
      " 5   GPA                1000 non-null   float64\n",
      " 6   Research           1000 non-null   int64  \n",
      " 7   Chance of Admit    1000 non-null   float64\n",
      "dtypes: float64(4), int64(4)\n",
      "memory usage: 62.6 KB\n",
      "None\n",
      "\n",
      "\n",
      "INFORMAÇÕES ESTATÍSTICAS\n",
      "         GRE Score  TOEFL Score  University Rating          SOP         LOR   \\\n",
      "count  1000.000000  1000.000000        1000.000000  1000.000000  1000.000000   \n",
      "mean    315.840000   106.459000           3.053000     2.997000     3.014400   \n",
      "std      15.083432     8.449954           1.421341     1.163239     1.163136   \n",
      "min     290.000000    92.000000           1.000000     1.000000     1.000000   \n",
      "25%     303.000000    99.000000           2.000000     2.000000     2.000000   \n",
      "50%     316.000000   107.000000           3.000000     3.000000     3.000000   \n",
      "75%     329.000000   114.000000           4.000000     4.000000     4.000000   \n",
      "max     340.000000   120.000000           5.000000     5.000000     5.000000   \n",
      "\n",
      "               GPA     Research  Chance of Admit  \n",
      "count  1000.000000  1000.000000      1000.000000  \n",
      "mean      3.027160     0.517000         0.729223  \n",
      "std       0.582774     0.499961         0.095161  \n",
      "min       2.000000     0.000000         0.491000  \n",
      "25%       2.530000     0.000000         0.655000  \n",
      "50%       3.025000     1.000000         0.728500  \n",
      "75%       3.550000     1.000000         0.801000  \n",
      "max       4.000000     1.000000         0.970000  \n"
     ]
    }
   ],
   "source": [
    "# Informações do dataframe\n",
    "print(f'Há {admission_df.shape[0]} linhas e {admission_df.shape[1]} colunas.')\n",
    "print('\\n')\n",
    "print('INFORMAÇÕES TÉCNICAS')\n",
    "print(admission_df.info())\n",
    "print('\\n')\n",
    "print('INFORMAÇÕES ESTATÍSTICAS')\n",
    "print(admission_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180ddadb-3897-4e9c-8e7b-36405e7448a9",
   "metadata": {},
   "source": [
    "### Análise exploratória dos dados (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25d0e4b-5819-485e-8004-8ec84a6ef7ff",
   "metadata": {},
   "source": [
    "Podemos observar que a maioria das universidades são nota 3 com uma variância de aproximadamente 1.4, logo os alunos admitidos estarão entrando em faculdades com boa reputação. Para isso, a maioria dos alunos conta com notas no TOEFL e GRE (Graduate Record Examination) de 315.8 e 106.4, respectivamente. Para ser aprovado nestes exames é necessário uma nota igual ou superior a 320 no GRE (nesta prova não há um número certo, sendo essa pontuação considerada boa para o exame) e 90 no TOEFL (também não é preciso, apenas uma média considerada aceitável).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a1c795-93b5-4a9a-b71f-7a22acda6596",
   "metadata": {},
   "source": [
    "### Modelo de regressão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d325f49a-0e30-4ea2-a967-cde37f4690d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Há 800 dados de features para treino.\n",
      "Há 200 dados de features para teste.\n",
      "Há 800 dados de target para treino.\n",
      "Há 200 dados de target para teste.\n"
     ]
    }
   ],
   "source": [
    "# Importando função para separar treino e teste\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separando as features do target\n",
    "X = admission_df.drop(columns='Chance of Admit') # features\n",
    "y = admission_df['Chance of Admit'] # target\n",
    "\n",
    "# Separando em treino e test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Conferindo o shape(quantidade) de cada\n",
    "print(f'Há {X_train.shape[0]} dados de features para treino.')\n",
    "print(f'Há {X_test.shape[0]} dados de features para teste.')\n",
    "print(f'Há {y_train.shape[0]} dados de target para treino.')\n",
    "print(f'Há {y_test.shape[0]} dados de target para teste.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca51223-bb67-4e6c-a2bd-f259bf07325a",
   "metadata": {},
   "source": [
    "Como pode-se perceber nas colunas, há dados que não estão normalizados entre si, com valores discrepantes. Para isso iremos normalizá-los com a função *StandardScaler* da ScikitLearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff5ec895-1865-46b3-9c1b-ad6c06c696d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got scalar array instead:\narray=StandardScaler().\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m model = LinearRegression()\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Modelando a variável com nossos dados de treino\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:618\u001b[39m, in \u001b[36mLinearRegression.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    614\u001b[39m n_jobs_ = \u001b[38;5;28mself\u001b[39m.n_jobs\n\u001b[32m    616\u001b[39m accept_sparse = \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.positive \u001b[38;5;28;01melse\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mcsr\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcsc\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcoo\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m618\u001b[39m X, y = \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    619\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    620\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    621\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    623\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    624\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    625\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    626\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    628\u001b[39m has_sw = sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    629\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_sw:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2971\u001b[39m, in \u001b[36mvalidate_data\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2969\u001b[39m         y = check_array(y, input_name=\u001b[33m\"\u001b[39m\u001b[33my\u001b[39m\u001b[33m\"\u001b[39m, **check_y_params)\n\u001b[32m   2970\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2971\u001b[39m         X, y = \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2972\u001b[39m     out = X, y\n\u001b[32m   2974\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params.get(\u001b[33m\"\u001b[39m\u001b[33mensure_2d\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:1368\u001b[39m, in \u001b[36mcheck_X_y\u001b[39m\u001b[34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[39m\n\u001b[32m   1362\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1363\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m requires y to be passed, but the target y is None\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1364\u001b[39m     )\n\u001b[32m   1366\u001b[39m ensure_all_finite = _deprecate_force_all_finite(force_all_finite, ensure_all_finite)\n\u001b[32m-> \u001b[39m\u001b[32m1368\u001b[39m X = \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1369\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1370\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1371\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1372\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1373\u001b[39m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1374\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1375\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1376\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1377\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1378\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1379\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1380\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1381\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1382\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mX\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1383\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1385\u001b[39m y = _check_y(y, multi_output=multi_output, y_numeric=y_numeric, estimator=estimator)\n\u001b[32m   1387\u001b[39m check_consistent_length(X, y)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:1068\u001b[39m, in \u001b[36mcheck_array\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1065\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ensure_2d:\n\u001b[32m   1066\u001b[39m     \u001b[38;5;66;03m# If input is scalar raise error\u001b[39;00m\n\u001b[32m   1067\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m array.ndim == \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1068\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1069\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mExpected 2D array, got scalar array instead:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33marray=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1070\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1071\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1072\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mif it contains a single sample.\u001b[39m\u001b[33m\"\u001b[39m.format(array)\n\u001b[32m   1073\u001b[39m         )\n\u001b[32m   1074\u001b[39m     \u001b[38;5;66;03m# If input is 1D raise error\u001b[39;00m\n\u001b[32m   1075\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m array.ndim == \u001b[32m1\u001b[39m:\n\u001b[32m   1076\u001b[39m         \u001b[38;5;66;03m# If input is a Series-like object (eg. pandas Series or polars Series)\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: Expected 2D array, got scalar array instead:\narray=StandardScaler().\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "# Importando alforitmo e função importantes para performance do modelo\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit(X_train)\n",
    "X_test_scaled = scaler.fit(X_test)\n",
    "\n",
    "# Instanciando uma variável para a função da regressão linear\n",
    "model = LinearRegression()\n",
    "\n",
    "# Modelando a variável com nossos dados de treino\n",
    "model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fb6918-8b09-48c8-b2db-39a02fe741b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando nossas predições\n",
    "y_pred = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8f411c-779c-4a1b-a9c9-71abdfde9ffc",
   "metadata": {},
   "source": [
    "Agora que treinamos e testamos nosso modelo, vamos avaliá-lo!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856ba14a-de23-4f45-9200-33c2c68d75e3",
   "metadata": {},
   "source": [
    "### Avaliando o modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21db8606-df5c-441f-8ee4-d0e113d39abf",
   "metadata": {},
   "source": [
    "Vamos começar plotando um gráfico de dispersão, mostrando o valor real X valor predito, e uma linha que representa quando o modelo acerta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cfb745-3389-4f96-bdb4-85a0eee20c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotando o gráfico de dispersão\n",
    "plt.scatter(y_test, y_pred)\n",
    "# Criando a linha para melhor análise\n",
    "plt.plot([y_test.min(), y_test.max()], \n",
    "                [y_test.min(), y_test.max()], \n",
    "                'r--', lw=3)\n",
    "# Mostrando o gráfico no nosso output\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1a2a4b-46f3-4aa5-89b6-17821dd3f404",
   "metadata": {},
   "source": [
    "Visualmente, podemos ver que o modelo parece ter performado bem. Para sabermos melhor, vamosm utilizar de ferramentas estatísticas para avaliar!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5a60c6-35be-40a0-8172-0c1c0ae55d60",
   "metadata": {},
   "source": [
    "#### Usando medidas estatísticas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5a05fd-4093-4c3c-900d-49cabf2f1f6c",
   "metadata": {},
   "source": [
    "Vamos utilizar a validação cruzada para avaliar o modelo e depois mostrar as correlações das colunas com o target selecionado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed5879b-45fc-4c35-9e46-2b59b663d205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validação cruzada\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Invocando a função\n",
    "cross_val = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='r2')\n",
    "# Printando os resultados no output\n",
    "print(f'R2 ajustado: {cross_val.mean():.3f} (+/- {cross_val.std():.3f})')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c58848-c69a-47ef-8c12-8e1b7afe1b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlações com a coluna 'Chance of Admit' (target)\n",
    "correlation = admission_df.corr()['Chance of Admit']\n",
    "print(correlation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fd6f0a-58e5-44dc-990a-370a044cd5ea",
   "metadata": {},
   "source": [
    "## Conclusão"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d24c75-68e1-4ae4-8e3b-25d4b9554443",
   "metadata": {},
   "source": [
    "Pode-se concluir que o nosso modelo, dentro dos dados treinados, performou muito bem. Estou satisfeito com o resultado mas mesmo assim precisamos de dados externos para validar o modelo, ver se realmente ele está treinado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a209788-4078-44b3-a0f3-d4e57d316887",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
